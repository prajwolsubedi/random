{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5CDO1M5HsI0hFKmXYzefD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwolsubedi/random/blob/main/Rick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ7eadopNSEb",
        "outputId": "3f8ff372-9eb5-40b5-e16c-abdea19e33ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.13.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.15 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Downloading gradientai-1.13.1-py3-none-any.whl (410 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/410.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.7/410.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7mQ7qOsfSQZ",
        "outputId": "c07e806f-59b4-453c-c3db-a529e9c88522"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_content = \"\"\"\n",
        "GRADIENT_ACCESS_TOKEN=JJaDJjOZmIrNDgvXyJ6VMy2cjIecGWp4\n",
        "GRADIENT_WORKSPACE_ID=aa6fce07-26ca-49ab-a4f8-777e45f21aae_workspace\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/.env\", \"w\") as f:\n",
        "    f.write(env_content)"
      ],
      "metadata": {
        "id": "E5g4c3jMfzTf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "# Load environment variables from .env file located in /content\n",
        "other_secret = os.getenv(\"OTHER_SECRET\")\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = os.getenv(\"GRADIENT_ACCESS_TOKEN\")\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = os.getenv(\"GRADIENT_WORKSPACE_ID\")"
      ],
      "metadata": {
        "id": "OmCXrKh_PxVk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gitignore_content = \"\"\"\n",
        ".env\n",
        "*.pyc\n",
        "__pycache__/\n",
        ".ipynb_checkpoints/\n",
        ".config/\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/.gitignore\", \"w\") as f:\n",
        "    f.write(gitignore_content)\n"
      ],
      "metadata": {
        "id": "9BRk4aRIhZdx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/.gitignore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHb3hW2qiFRu",
        "outputId": "e7abbc94-609c-440b-b7ac-83488c64d8c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ".env\n",
            "*.pyc\n",
            "__pycache__/\n",
            ".ipynb_checkpoints/\n",
            ".config/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for parsing csv source file\n",
        "import csv\n",
        "\n",
        "#gradient library\n",
        "from gradientai import Gradient\n",
        "\n",
        "path_to_csv_file = \"/content/sample_data/Rick.csv\"\n"
      ],
      "metadata": {
        "id": "TQmR_rTYQvqe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find pairs of lines where someone else speaks, then Rick speaks\n",
        "# append them as two separate lines in rows_to_keep\n",
        "print(\"Parsing data...\")\n",
        "rows_to_keep = []\n",
        "with open(path_to_csv_file, encoding=\"utf-8-sig\") as f:\n",
        "  reader = csv.DictReader(f, delimiter=\",\")\n",
        "  last_row = None\n",
        "  for row in reader:\n",
        "    if \"Rick\" == row[\"name\"] and last_row is not None:\n",
        "      rows_to_keep.append(last_row)\n",
        "      rows_to_keep.append(row)\n",
        "      last_row = None\n",
        "    else:\n",
        "      last_row = row\n",
        "\n",
        "# create a role-playing prompt for training and\n",
        "# later for prompting\n",
        "role_play_prompt = \"You are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\"\n",
        "\n",
        "# combine pairs of rows from above to\n",
        "# create prompt + reponse on each line\n",
        "# using prompt template in 'lines' array\n",
        "lines = []\n",
        "for i in range(0, len(rows_to_keep), 2):\n",
        "  prompt = rows_to_keep[i]\n",
        "  response = rows_to_keep[i+1]\n",
        "  start_str = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n\"\n",
        "  prompt = prompt[\"line\"].replace('\"','\\\\\"')\n",
        "  mid_str = '''\\n\\n### Response:\\n'''\n",
        "  response = response[\"line\"].replace('\"','\\\\\"')\n",
        "  end_str = '''</s>'''\n",
        "  total_line = start_str + prompt + mid_str + response + end_str\n",
        "  # each line of training data is a simple object: 'inputs' and actual training string\n",
        "  obj = {\n",
        "    \"inputs\" : total_line\n",
        "  }\n",
        "  lines.append(obj)\n",
        "  # print(total_line) # comment in to see how the formatted lines look\n",
        "    # these lines could also be written to a jsonl file for use\n",
        "    # with the command line interface\n",
        "print(f\"Generated {len(lines)} lines to fine-tune\")\n",
        "print(f\"Example training line: {lines[0]}\")\n",
        "\n",
        "# split up the lines into manageable chunks\n",
        "lines_per_chunk = 20\n",
        "all_chunks = []\n",
        "for line in lines:\n",
        "  if len(all_chunks) == 0 or len(all_chunks[-1]) == lines_per_chunk:\n",
        "    all_chunks.append([])\n",
        "  all_chunks[-1].append(line)\n",
        "\n",
        "# fine tune the adapter using the chunks of lines from above\n",
        "# loop contains a try block to handle network or other\n",
        "# processing errors gracefully\n",
        "print(f\"\\nFine-tuning model adapter\")\n",
        "gradient = Gradient()\n",
        "base = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "my_adapter = base.create_model_adapter(name=\"rickbot\")\n",
        "print(f\"Created model with ID {my_adapter.id}\")\n",
        "for i in range(len(all_chunks)):\n",
        "  try:\n",
        "    print(f\"Fine-tuning chunk {i} of {len(all_chunks) - 1}\")\n",
        "    my_adapter.fine_tune(samples=all_chunks[i])\n",
        "  except Exception as error:\n",
        "    try:\n",
        "      error_pieces = str(error).split(\"\\n\")\n",
        "      if len(error_pieces) > 1:\n",
        "        print(f\"*** Error processing chunk {i}: {error_pieces[0]} {error_pieces[1]}\")\n",
        "      else:\n",
        "        print(f\"*** Unknown error on chunk {i}: {error}\")\n",
        "    except KeyboardInterrupt:\n",
        "      break\n",
        "    except Exception as inner_error:\n",
        "      print(inner_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqfBKP-TUDxu",
        "outputId": "c10fdb24-ed8c-41b4-9b71-10466e7aa362"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "Generated 370 lines to fine-tune\n",
            "Example training line: {'inputs': '<s>### Instruction:\\nYou are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\\n\\n###Input:\\nWhat, Rick? What’s going on?\\n\\n### Response:\\nI got a surprise for you, Morty.</s>'}\n",
            "\n",
            "Fine-tuning model adapter\n",
            "Created model with ID 7276ad1b-2e2e-4901-a274-9c1d721f7f70_model_adapter\n",
            "Fine-tuning chunk 0 of 18\n",
            "*** Error processing chunk 0: (422) Reason: unknown\n",
            "Fine-tuning chunk 1 of 18\n",
            "Fine-tuning chunk 2 of 18\n",
            "*** Error processing chunk 2: (422) Reason: unknown\n",
            "Fine-tuning chunk 3 of 18\n",
            "Fine-tuning chunk 4 of 18\n",
            "Fine-tuning chunk 5 of 18\n",
            "Fine-tuning chunk 6 of 18\n",
            "*** Error processing chunk 6: (422) Reason: unknown\n",
            "Fine-tuning chunk 7 of 18\n",
            "Fine-tuning chunk 8 of 18\n",
            "Fine-tuning chunk 9 of 18\n",
            "Fine-tuning chunk 10 of 18\n",
            "Fine-tuning chunk 11 of 18\n",
            "*** Error processing chunk 11: (500) Reason: Internal Server Error\n",
            "Fine-tuning chunk 12 of 18\n",
            "Fine-tuning chunk 13 of 18\n",
            "Fine-tuning chunk 14 of 18\n",
            "Fine-tuning chunk 15 of 18\n",
            "Fine-tuning chunk 16 of 18\n",
            "Fine-tuning chunk 17 of 18\n",
            "Fine-tuning chunk 18 of 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "role_play_prompt = \"You are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\"\n",
        "query = \"Guess my name ...\"\n",
        "templated_query = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n{query}\\n\\n### Response:\\n\"\n",
        "response = my_adapter.complete(query=templated_query, max_generated_token_count=500)\n",
        "print(f\"> {query}\\n> {response.generated_output}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te_MNtLxY8TS",
        "outputId": "d80e18a8-e445-4eaf-facb-e7df52af7693"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Guess my name ...\n",
            "> I'm gonna go with ...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_adapter.delete()"
      ],
      "metadata": {
        "id": "4gC7v5sTaYLE"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}